{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d75041d0",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f4c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b09dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Models:\n",
    "    - 'RetinaNet'\n",
    "    - 'Faster-RCNN'\n",
    "\n",
    "Backbones:\n",
    "    - 'resnet18'    - 'resnet101'          - 'resnext101_32x8d'\n",
    "    - 'resnet34'    - 'resnet152'          - 'wide_resnet50_2'\n",
    "    - 'resnet50'    - 'resnext50_32x4d'    - 'wide_resnet101_2'\n",
    "'''\n",
    "\n",
    "model = 'Faster-RCNN'#'RetinaNet'\n",
    "backbone = 'resnet18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab27b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Standard Configuration:\n",
    "\n",
    "    - epochs: (Int) Number of epochs to train\n",
    "    \n",
    "    - use_gpu: (Bool) If False, training on CPU\n",
    "    \n",
    "    - pretrained_backbone: (Bool) If True, loads \n",
    "                pretrained state dict to backbone\n",
    "                \n",
    "    - num_classes: (Int) Number of classes on \n",
    "                dataset + 1 (Class 0 represents \n",
    "                backround)\n",
    "                \n",
    "    - train_batch_size: (Int) Batch size used\n",
    "                while training\n",
    "                \n",
    "    - train_size: (Float) Percentage of training \n",
    "                size division. If train_size == 0.7, \n",
    "                train_set will be 70% of given dataset \n",
    "                and test_set, 30% of it.\n",
    "                \n",
    "    - lr_scheduler: (torch.optim) Learning-Rate \n",
    "                Scheduler. If None, the learning-rate will\n",
    "                be kept constant.\n",
    "                \n",
    "    - checkpoints_path: (String) Path for saving \n",
    "                checkpoints. If directory doesnt exist,\n",
    "                it'll be created.\n",
    "                \n",
    "    - dataset_path: Annotations file directory path. \n",
    "    \n",
    "                Directory must contain files:\n",
    "                \n",
    "                  File Name:                File Column Data:\n",
    "                    - 'test.txt':               (String) Path\n",
    "                    - 'test_bbox.txt':          (Int, Int, Int, Int) X1, Y1, X2, Y2\n",
    "                    - 'test_cate.txt':          (Int) Class\n",
    "                    - 'train.txt':              (String) Path\n",
    "                    - 'train_bbox.txt':         (Int, Int, Int, Int) X1, Y1, X2, Y2\n",
    "                    - 'train_cate.txt':         (Int) Class\n",
    "                    - 'val.txt':                (String) Path\n",
    "                    - 'val_bbox.txt':           (Int, Int, Int, Int) X1, Y1, X2, Y2 \n",
    "                    - 'val_cate.txt':           (Int) Class\n",
    "                \n",
    "    - data_augmentation: (Int) Data-Augmentation Type.\n",
    "                - If 0, no data augmentation will be applied\n",
    "                - If 1, apply color jitter at (0.4, 0.4, 0.4)\n",
    "                - If 2, apply random horizontal flip with p=0.5\n",
    "                - If 3, apply both 1 and 2\n",
    "'''\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "use_gpu = True\n",
    "pretrained_backbone = True\n",
    "\n",
    "num_classes = 50\n",
    "train_batch_size = 8\n",
    "\n",
    "train_size = 0.7\n",
    "\n",
    "lr_scheduler = None\n",
    "#lr_scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "checkpoints_path = './checkpoints'\n",
    "\n",
    "dataset_path = '../data/Annotations/'\n",
    "\n",
    "data_augmentation = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fae5ea",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68aae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2afe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c30f454",
   "metadata": {},
   "source": [
    "#### Type 0: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Base'\n",
    "Transform = None\n",
    "\n",
    "transforms.append((Transform, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b6aa34",
   "metadata": {},
   "source": [
    "#### Type 1: Color Jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Color_Jitter'\n",
    "Transform = torchvision.transforms.ColorJitter(0.4, 0.4, 0.4)\n",
    "\n",
    "transforms.append((Transform, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6b8aa4",
   "metadata": {},
   "source": [
    "#### Type 2: Horizontal Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd6066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Horizontal_Flip'\n",
    "Tranform = torchvision.transforms.RandomHorizontalFlip(p=0.5)\n",
    "\n",
    "transforms.append((Transform, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435bc1db",
   "metadata": {},
   "source": [
    "#### Type 3 (mixed): HorizontalFlip & Color Jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd22af",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Jitter_and_Flip'\n",
    "\n",
    "Jitter_Transform = torchvision.transforms.ColorJitter(0.4, 0.4, 0.4)\n",
    "Flip_Tranform = torchvision.transforms.RandomHorizontalFlip(p=0.5)\n",
    "\n",
    "Transform = torchvision.transforms.Compose([Jitter_Transform,\n",
    "                                            Flip_Tranform])\n",
    "\n",
    "transforms.append((Transform, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2592a1bd",
   "metadata": {},
   "source": [
    "### Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transform, da_type = transforms[data_augmentation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a483240",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefix=f'{model}_{da_type}_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc485104",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37cf540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dataset.ClothingDataset(dataset_path, \n",
    "                                    train='train', \n",
    "                                    transforms=Transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5dfd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f97e2f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5187f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from utils import trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761541b",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ad40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Net Construction\n",
    "\n",
    "    Builds Network with the given paremeters.\n",
    "'''\n",
    "\n",
    "trainable_backbone_layers = 0\n",
    "\n",
    "backbone = torchvision.models.detection.backbone_utils.resnet_fpn_backbone(backbone_name=backbone,\n",
    "                                                                           pretrained=pretrained_backbone,\n",
    "                                                                           returned_layers=[2, 3, 4],\n",
    "                                                                           extra_blocks=torchvision.ops.feature_pyramid_network.LastLevelP6P7(256, 256),\n",
    "                                                                           trainable_layers=trainable_backbone_layers,\n",
    "                                                                           norm_layer=torchvision.ops.misc.BatchNorm2d)\n",
    "if model == 'Faster-RCNN':\n",
    "    model = torchvision.models.detection.FasterRCNN(backbone, \n",
    "                                                   num_classes)\n",
    "else:\n",
    "    model = torchvision.models.detection.RetinaNet(backbone, \n",
    "                                                   num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64677f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Trainer Builder\n",
    "\n",
    "    Creates a Trainer Object with the given model and parameters.\n",
    "    \n",
    "    A Trainer Object is a simple implementation of NN training for\n",
    "    object detection. It implements the ability to train and validate \n",
    "    a model. It does not evaluate on test sets.\n",
    "'''\n",
    "\n",
    "train = trainer.Trainer(model=model,\n",
    "                        dataset=train_set,\n",
    "                        n_classes=num_classes, \n",
    "                        train_batch_size=train_batch_size, \n",
    "                        train_size=train_size, \n",
    "                        lr_scheduler=lr_scheduler, \n",
    "                        use_gpu=use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faa1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training stage\n",
    "\n",
    "    Calls the training Train method. Returns a dict\n",
    "    of epoch-wise training and validation mean-loss.\n",
    "    \n",
    "    train_loss: dict(list, list)\n",
    "                  Keys:\n",
    "                     - 'loss_classifier': list\n",
    "                     - 'loss_box':        list\n",
    "\n",
    "    validation_loss: dict(list, list)\n",
    "                       Keys:\n",
    "                          - 'loss_classifier': list\n",
    "                          - 'loss_box':        list\n",
    "'''\n",
    "\n",
    "train_loss, validation_loss = train.train(epochs=epochs, \n",
    "                                          checkpoints_path=checkpoints_path, \n",
    "                                          checkpoint_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ded3f7",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cfd637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593c34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loss Recovery\n",
    "\n",
    "    Recover the train and validation losses \n",
    "    returned by the trainer.\n",
    "\n",
    "    train_loss: dict(list, list)\n",
    "                  Keys:\n",
    "                     - 'loss_classifier': list\n",
    "                     - 'loss_box':        list\n",
    "\n",
    "    validation_loss: dict(list, list)\n",
    "                       Keys:\n",
    "                          - 'loss_classifier': list\n",
    "                          - 'loss_box':        list\n",
    "'''\n",
    "\n",
    "train_loss_classifier = train_loss['loss_classifier']\n",
    "train_loss_box = train_loss['loss_box']\n",
    "validation_loss_classifier = validation_loss['loss_classifier']\n",
    "validation_loss_box = validation_loss['loss_box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification Plotting\n",
    "\n",
    "    Plots the training and validation epoch-wise \n",
    "    classification loss. \n",
    "'''\n",
    "\n",
    "plt.title(f'Training Classification Losses with {model} {da_type} Model')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "clip_max = np.max(validation_loss_classifier)\n",
    "plt.plot(np.clip(train_loss_classifier, 0, clip_max))\n",
    "plt.plot(np.clip(validation_loss_classifier, 0, clip_max))\n",
    "plt.plot(np.argmin(validation_loss_classifier), np.min(validation_loss_classifier),'ro') \n",
    "plt.text(np.argmin(validation_loss_classifier), np.min(validation_loss_classifier)+0.01,\n",
    "         '({}, {})'.format(np.argmin(validation_loss_classifier), np.min(validation_loss_classifier)))\n",
    "plt.axhline(y=np.min(validation_loss_classifier), color='r', linestyle='-', linewidth=.5)\n",
    "plt.legend(['Train Loss', 'Validation Loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d72286",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Box Plotting\n",
    "\n",
    "    Plots the training and validation epoch-wise \n",
    "    box loss. \n",
    "'''\n",
    "\n",
    "plt.title(f'Training Box Losses with {model} {da_type} Model')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "clip_max = np.max(validation_loss_box)\n",
    "plt.plot(np.clip(train_loss_box, 0, clip_max))\n",
    "plt.plot(np.clip(validation_loss_box, 0, clip_max))\n",
    "plt.plot(np.argmin(validation_loss_box), np.min(validation_loss_box),'ro') \n",
    "plt.text(np.argmin(validation_loss_box), np.min(validation_loss_box)+0.01,\n",
    "         '({}, {})'.format(np.argmin(validation_loss_box), np.min(validation_loss_box)))\n",
    "plt.axhline(y=np.min(validation_loss_box), color='r', linestyle='-', linewidth=.5)\n",
    "plt.legend(['Train Loss', 'Validation Loss'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
